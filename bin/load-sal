#!/usr/bin/env python

# The util funcs in here should be pushed somewhere centralized in
# pbcommand?
import iso8601
from collections import defaultdict, namedtuple
import pprint
from pbcommand.services import ServiceAccessLayer as Sal, JobTypes, JobStates

ServiceJob = namedtuple("ServiceJob", 'id uuid name state path job_type created_at')


def _to_service_job(d):
    def sx(x):
        return d[x]

    def se(x):
        return sx(x).encode('ascii', 'ignore')

    def to_t(x):
        return iso8601.parse_date(se(x))
    return ServiceJob(sx('id'), sx('uuid'), se('name'), se('state'),
                      se('path'), se('jobTypeId'), to_t('createdAt'))

SALS = {}


def register_sal(host, port):
    s = Sal(host, port)
    SALS[host] = s
    return s

s = register_sal("localhost", 8070)
local_sal = register_sal("localhost", 8070)
beta_sal = register_sal("smrtlink-beta", 8081)
alpha_sal = register_sal("smrtlink-alpha", 8081)
bihourly_sal = register_sal("smrtlink-bihourly", 8081)
nightly_sal = register_sal("smrtlink-bihourly", 8081)
print "Loaded Service AccessLayers, {x}".format(x=SALS.keys())
print pprint.pformat(SALS)


def _jobs_by_state_gen(sal, job_states):
    """:type sal: ServiceAccessLayer"""

    states = job_states if isinstance(job_states, (tuple, list)) else [job_states]

    jobs = sal.get_analysis_jobs()
    for job in jobs:
        sjob = _to_service_job(job)
        if sjob.state in states:
            yield sjob


def get_failed_jobs(sal):
    return sorted(_jobs_by_state_gen(sal, JobStates.FAILED), key=lambda x: x.created_at, reverse=True)


def jobs_summary(jobs):
    """dict(state) -> count (int) """
    states_counts = defaultdict(lambda : 0)
    for job in jobs:
        state = job['state']
        states_counts[state] += 1

    return states_counts


def to_jobs_summary(jobs, header=None):
    """Return string of jobs summary"""
    header = "Jobs" if header is None else header

    outs = []
    x = outs.append
    states_counts = jobs_summary(jobs)
    x("{h} {n}".format(n=len(jobs), h=header))
    for s, c in states_counts.iteritems():
        x("State {s} {c}".format(c=c, s=s))

    return "\n".join(outs)


def to_all_job_types_summary(sal, sep="*****"):

    # only  use a subset of the job types

    funcs = [(JobTypes.IMPORT_DS, sal.get_import_dataset_jobs),
             (JobTypes.MERGE_DS, sal.get_merge_dataset_jobs),
             (JobTypes.CONVERT_FASTA, sal.get_fasta_convert_jobs),
             (JobTypes.PB_PIPE, sal.get_analysis_jobs)]

    outs = []
    x = outs.append
    x("All Job types Summary")
    x(sep)
    for name, func in funcs:
        out = to_jobs_summary(func(), header="{n} Jobs".format(n=name))
        x(out)
        x(sep)

    return "\n".join(outs)


def to_all_datasets_summary(sal, sep="****"):

    ds_types = [("SubreadSets", sal.get_subreadsets),
                ("HdfSubreadSets", sal.get_hdfsubreadsets),
                ("ReferenceSets", sal.get_referencesets),
                ("AlignmentSets", sal.get_alignmentsets),
                #("ConsensusSets", sal.get_ccsreadsets)
                ]

    outs = []
    x = outs.append
    x("Dataset Summary")
    x(sep)
    for name, func in ds_types:
        d = func()
        ndatasets = len(d)
        x("{n} {d}".format(n=name, d=ndatasets))

    return "\n".join(outs)


def to_sal_summary(sal):
    """:type sal: ServiceAccessLayer"""

    status = sal.get_status()
    outs = []

    x = outs.append

    sep = "-" * 10

    x(repr(sal))
    x("Status {s}".format(s=status['message']))
    x(sep)
    x(to_all_datasets_summary(sal, sep=sep))
    x(sep)
    x(to_all_job_types_summary(sal, sep=sep))

    return "\n".join(outs)


from IPython import embed
embed()
